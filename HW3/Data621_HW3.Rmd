---
title: "DATA 621 â€“ Business Analytics and Data Mining"
author: "VP"
date: "`r Sys.Date()`"
subtitle: 'Homework 3: Critical Thinking Group 2'
output:
  pdf_document: default
  word_document: default
  html_document:
    code_folding: hide
    df_print: paged
    highlight: tango
    theme: united
editor_options:
  chunk_output_type: inline
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
## load library
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("caret")) install.packages("caret") 
if (!require("knitr")) install.packages("knitr")
if (!require("pROC")) install.packages("pROC")
if (!require("gridExtra")) install.packages("gridExtra")
if (!require("car")) install.packages("car") 
if (!require("factoextra")) install.packages("factoextra")
if (!require("dplyr")) install.packages("dplyr")
if (!require("DT")) install.packages("DT") 
if (!require("caTools")) install.packages("caTools")

knitr::opts_chunk$set(echo = TRUE)
options("scipen" = 10)


```

## Step 1. 

Download the classification output data set.

```{r}
df <- read.csv("https://raw.githubusercontent.com/mkivenson/Business-Analytics-Data-Mining/master/Classification%20Project/crime-training-data_modified.csv")
kable(head(df,10), booktabs = T)
```

# Data Exploration


#### Summary

First, we take a look at a summary of the data. A few items of interest are revealed:

* There are no missing values in the dataset
* There are no immediately apparent outliers
* Expected clusters are of similar size (237 and 229). This is a necessary assumption for algorithms such as K-Means clustering.

```{r}
summary(df)
```



#### Boxplots

Next, we create boxplots of each of the features - color coded by the target variable. These boxplots reveal significant information about the predictor variables

* The `chas` dummy variable has most of its values at 0
* indus, zn, nox, age, dis, rad, tax, ptratio, lstat, and medv seem to have strong affects on the target variable  

```{r fig1, fig.height = 6, fig.width = 8, fig.align= 'center'}
grid.arrange(ggplot(df, aes(x = as.factor(target), y = zn, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = indus, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = chas, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = nox, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = rm, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = age, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = dis, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = rad, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = tax, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = ptratio, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = lstat, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ggplot(df, aes(x = as.factor(target), y = medv, fill = as.factor(target))) + geom_boxplot() + theme(legend.position = "none") ,
             ncol=4)
```



#### PCA Component Visualization

PCA can be used for classification, but for now, it will be used to visualize the clusters. First, the number of components will be selected based on the variances explained by each component.

Taking a look at the plot of percentages explained by each principal component, it seems like most of the variance can be explained by 2 principal components. 


```{r fig2, fig.height = 4, fig.width = 6, fig.align= 'center'}
df.pca <- prcomp(df[1:12], center = TRUE, scale. = TRUE)
fviz_eig(df.pca)
```


Using these two principal components, a scatterplot of the clusters can be created. Having two principal components makes it easier to distinguish between the two clusters, though there is some overlap.

```{r fig3, fig.height = 4, fig.width = 6, fig.align= 'center'}
fviz_pca_ind(df.pca,
             col.ind = as.factor(df$target), # Color by the quality of representation
             palette = c("#00AFBB",  "#FC4E07"),
             addEllipses = TRUE, 
             legend.title = "Target",
             labels = FALSE
             )
```





# Data Preparation

Since the dataset does not have any missing values and there are no outliers that particulary stand out, data preparation will be limited. However, we will locate and address any influential outliers using Cooks Distance. Outliers that have a Cooks distance outside the acceptable threshold of 4 / (N - k - 1) where N is the number of observations and k is the number of predictive variables, will be removed. 

#### Cooks Distance

```{r fig4, fig.height = 5, fig.width = 6, fig.align= 'center'}
mod <- lm(target ~ ., data=df)
cooksd <- cooks.distance(mod)
plot(cooksd, pch="*", cex=2, main="Influential Outliers by Cooks distance")
abline(h = 4 / (nrow(df) - ncol(df) - 1), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```


We remove the influencial outliers. Removing these outliers also makes the two primary components (visualized in the previous step) explain more of the variance in the data.

```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4 / (nrow(df) - ncol(df) - 1))])
df <- df[-influential, ]
```

## Building logistic regression

We will build a logistic classifer using generlized linear regresson with binomaial distribution. 

Lets evaluate the distribution of target class label and check whether the dataset is imbalanced or not. 

```{r}
table(df$target)
```

we see that both label 0 and label 1 is balanced and have nearly equal number of datapoints. 

Now lets split the given data set into 80% of training data and 20% testing data.
And build logistic classifer with the training set 


Model 1: All Variable

```{r}
split = sample.split(df$target, SplitRatio = 0.8)
training_set = subset(df, split == TRUE)
test_set = subset(df, split == FALSE)

model1 <- glm(target ~ ., data = training_set, family = "binomial")
summary(model1)

```


If I drop all non signifigant variables I am left with the following variables:nox, age, dis, rad, tax, pratio
Therefore I am going to build a model with thoses variables.  
Here is the summary for that model (model2)

```{r message=FALSE, warning=FALSE}
model2 <- glm(target~nox+ age+dis+ rad+tax+ptratio  , data =training_set, family="binomial" )
summary(model2)

```
If I drop all non signifigant variables I am left with the following variables:nox, age, pratio
Therefore I am going to build a model with thoses variables.  
Here is the summary for that model (model2)

```{r message=FALSE, warning=FALSE}
model3 <- glm(target~nox+ age+ rad+tax+ptratio  , data =training_set, family="binomial" )
summary(model3)

```

```{r message=FALSE, warning=FALSE}
model4 <- glm(target~nox+ age+ rad+tax  , data =training_set, family="binomial" )
summary(model4)

```

#Select Models:
I am going to select the model based on area under the ROC curve (A/K/A AUC) and AIC.  

```{r fig5, fig.height = 4, fig.width = 6, fig.align= 'center'}
roc(target~model1$fitted.values, data = training_set,plot = TRUE, main = "ROC CURVE", col= "blue",
    percent=TRUE,
    ci = TRUE, # compute AUC (of AUC by default)
    print.auc = TRUE)
model1$aic
```

The AIC for model1 is `r  model1$aic`

Model2 Variables in Model 2:  `nox + age+dis+ rad + tax + ptratio`
```{r fig6, fig.height = 4, fig.width = 6, fig.align= 'center' }
roc(target~model2$fitted.values, data = training_set, plot = TRUE, main = "ROC CURVE", col= "blue",percent=TRUE,
    ci = TRUE, # compute AUC (of AUC by default)
    print.auc = TRUE)
model2$aic
```

The AIC for model2 is `r  model2$aic`



Model3 Variables: `nox+ age+ rad+tax+ptratio`, 
```{r fig7, fig.height = 4, fig.width = 6, fig.align= 'center' } 
roc(target~model3$fitted.values, data = training_set, plot = TRUE, main = "ROC CURVE", col= "blue",percent=TRUE,
    ci = TRUE, # compute AUC (of AUC by default)
    print.auc = TRUE)
model3$aic
```

The AIC for model3 is `r  model3$aic`

Model4 Variables: `nox+ age+ rad+tax`, 
```{r fig8, fig.height = 4, fig.width = 6, fig.align= 'center' } 
roc(target~model4$fitted.values, data = training_set, plot = TRUE, main = "ROC CURVE", col= "blue",percent=TRUE,
    ci = TRUE, # compute AUC (of AUC by default)
    print.auc = TRUE)
model4$aic
```

The AIC for model4 is `r  model4$aic`


Based the fact that the area under the curve for model 2 and model 3 are virtually identical and the AIC for model 2 is about 1/2 the AIC for model 1 I am going to select model2.

